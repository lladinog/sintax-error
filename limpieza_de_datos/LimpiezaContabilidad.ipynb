{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225e1235",
   "metadata": {},
   "source": [
    "**Importar Librerías**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673c2a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0c083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np # Para np.nan\n",
    "import os # Importar el módulo os para manejar rutas de archivos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e1859",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abceeda",
   "metadata": {},
   "source": [
    "**Conexión a Base de Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8d18d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46eb397",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'db_connection'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdb_connection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_connection\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdb_connection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_engine\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'db_connection'"
     ]
    }
   ],
   "source": [
    "from db_connection import get_connection\n",
    "from db_connection import get_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5807d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4cdd5",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811838fe",
   "metadata": {},
   "source": [
    "**Limpieza y Análisis de Datosde Cada una de las Bases de Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216060f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e5941",
   "metadata": {},
   "source": [
    "***1. Tabla accounting_account_balances***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e3f77",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385ef95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_account_balances':\n",
      "  - id (bigint unsigned)\n",
      "  - code (double(16,15))\n",
      "  - accounting_id (bigint unsigned)\n",
      "  - name (varchar(255))\n",
      "  - initial_balance (double(18,6))\n",
      "  - final_balance (double(18,6))\n",
      "  - debit_movement (double(18,6))\n",
      "  - credit_movement (double(18,6))\n",
      "  - third_party_type_id (varchar(50))\n",
      "  - third_party_id (bigint unsigned)\n",
      "  - currency_id (varchar(255))\n",
      "  - year (int)\n",
      "  - month (int)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection() # Obtener una nueva conexión o reutilizar si get_connection maneja eso\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_account_balances;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_account_balances':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f007c",
   "metadata": {},
   "source": [
    "Eliminación de columna que no aportan información relevante (created_at, update_at)\n",
    "También se eliminan las constantes tales como (currency_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440af08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_account_balances'...\n",
      "Tabla 'accounting_account_balances' cargada exitosamente. Filas: 4499, Columnas: 15\n",
      "\n",
      "Eliminando columnas 'created_at', 'updated_at', y 'currency_id'...\n",
      "Columnas ['created_at', 'updated_at', 'currency_id'] eliminadas exitosamente.\n",
      "\n",
      "Columnas restantes en el DataFrame 'accounting_account_balances':\n",
      "['id', 'code', 'accounting_id', 'name', 'initial_balance', 'final_balance', 'debit_movement', 'credit_movement', 'third_party_type_id', 'third_party_id', 'year', 'month']\n",
      "\n",
      "Primeras 5 filas del DataFrame 'accounting_account_balances' después de la eliminación:\n",
      "   id  code  accounting_id    name  initial_balance  final_balance  \\\n",
      "0   1   1.0              1  Activo              0.0  -4.500000e+04   \n",
      "1   2   1.0              1  Activo              0.0   3.550000e+06   \n",
      "2   3   1.0              1  Activo              0.0   0.000000e+00   \n",
      "3   4   1.0              1  Activo              0.0   3.730769e+03   \n",
      "4   5   1.0              1  Activo              0.0   2.781800e+04   \n",
      "\n",
      "   debit_movement  credit_movement third_party_type_id  third_party_id  year  \\\n",
      "0       3525000.0     3.570000e+06             Contact               1  2024   \n",
      "1       3570000.0     2.000000e+04             Contact               1  2024   \n",
      "2         59500.0     5.950000e+04             Contact              13  2024   \n",
      "3         59500.0     5.576923e+04             Contact              13  2024   \n",
      "4        149940.0     1.221220e+05             Contact              34  2024   \n",
      "\n",
      "   month  \n",
      "0      2  \n",
      "1      2  \n",
      "2      2  \n",
      "3      2  \n",
      "4      2  \n",
      "\n",
      "Proceso de eliminación de columnas completado.\n"
     ]
    }
   ],
   "source": [
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_account_balances' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_account_balances'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_account_balances = pd.read_sql('SELECT * FROM accounting_account_balances', engine)\n",
    "    print(f\"Tabla 'accounting_account_balances' cargada exitosamente. Filas: {df_account_balances.shape[0]}, Columnas: {df_account_balances.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_account_balances': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Definir y eliminar las columnas ---\n",
    "print(\"\\nEliminando columnas 'created_at', 'updated_at', y 'currency_id'...\")\n",
    "\n",
    "columns_to_drop = ['created_at', 'updated_at', 'currency_id']\n",
    "\n",
    "# Usamos .drop() para eliminar las columnas.\n",
    "# `axis=1` indica que estamos eliminando columnas (no filas).\n",
    "# `inplace=True` modificaría el DataFrame original directamente.\n",
    "# Si quieres crear un nuevo DataFrame y mantener el original, omite `inplace=True`\n",
    "# y asigna el resultado a una nueva variable, por ejemplo:\n",
    "# df_account_balances_cleaned = df_account_balances.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Para este ejemplo, modificaremos el DataFrame original para que sigas trabajando con él\n",
    "df_account_balances.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Columnas {columns_to_drop} eliminadas exitosamente.\")\n",
    "\n",
    "# --- Paso 3: Verificar las columnas restantes ---\n",
    "print(f\"\\nColumnas restantes en el DataFrame 'accounting_account_balances':\")\n",
    "print(df_account_balances.columns.tolist())\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas del DataFrame modificado ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'accounting_account_balances' después de la eliminación:\")\n",
    "print(df_account_balances.head())\n",
    "\n",
    "print(\"\\nProceso de eliminación de columnas completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a9686",
   "metadata": {},
   "source": [
    "Conversión de la tabla a formato csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd16ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- Paso 1: Recargar la tabla \\'accounting_account_balances\\' y aplicar las transformaciones ---\\n# Es CRUCIAL que el DataFrame refleje las últimas operaciones (ej. eliminación de columnas)\\n# Si tu script anterior ya dejó \\'df_account_balances\\' en el estado deseado, puedes omitir esta recarga y transformación.\\n# Sin embargo, para asegurar la reproducibilidad y que el CSV contenga el DataFrame limpio,\\n# es buena práctica recargar y aplicar las transformaciones si este es un script independiente.\\n\\nprint(\"Preparando el DataFrame \\'accounting_account_balances\\' para exportación...\")\\ntry:\\n    engine = get_engine()\\n    df_account_balances = pd.read_sql(\\'SELECT * FROM accounting_account_balances\\', engine)\\n\\n    # Aplicar las eliminaciones de columnas que definimos previamente\\n    columns_to_drop = [\\'created_at\\', \\'updated_at\\', \\'currency_id\\']\\n    # Filtrar solo las columnas que realmente existen en el DataFrame para evitar errores si ya fueron eliminadas\\n    existing_columns_to_drop = [col for col in columns_to_drop if col in df_account_balances.columns]\\n\\n    if existing_columns_to_drop:\\n        df_account_balances.drop(columns=existing_columns_to_drop, inplace=True)\\n        print(f\"Columnas {existing_columns_to_drop} eliminadas antes de exportar.\")\\n    else:\\n        print(\"Las columnas a eliminar (\\'created_at\\', \\'updated_at\\', \\'currency_id\\') no se encontraron o ya fueron eliminadas.\")\\n\\n    print(f\"DataFrame \\'accounting_account_balances\\' listo para exportación. Filas: {df_account_balances.shape[0]}, Columnas: {df_account_balances.shape[1]}\")\\n\\nexcept Exception as e:\\n    print(f\"Error al preparar el DataFrame \\'accounting_account_balances\\': {e}\")\\n    raise # Relanzar la excepción para detener la ejecución si falla.\\n\\n# --- Paso 2: Definir la ruta y el nombre del archivo CSV ---\\n# Puedes ajustar la ruta donde quieres guardar el archivo.\\n# \\'os.getcwd()\\' te da el directorio de trabajo actual donde se está ejecutando el script.\\noutput_directory = os.getcwd() # Guarda en el mismo directorio del script\\ncsv_filename = \\'accounting_account_balances_cleaned.csv\\'\\noutput_filepath = os.path.join(output_directory, csv_filename)\\n\\n# --- Paso 3: Exportar el DataFrame a un archivo CSV ---\\nprint(f\"\\nExportando el DataFrame a CSV: \\'{output_filepath}\\'...\")\\ntry:\\n    df_account_balances.to_csv(output_filepath, index=False, encoding=\\'utf-8\\')\\n    print(\"¡DataFrame exportado a CSV exitosamente!\")\\n    print(f\"Puedes encontrar el archivo en: {output_filepath}\")\\nexcept Exception as e:\\n    print(f\"Error al exportar el DataFrame a CSV: {e}\")\\n\\nprint(\"\\nProceso de exportación a CSV completado.\")'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# --- Paso 1: Recargar la tabla 'accounting_account_balances' y aplicar las transformaciones ---\n",
    "# Es CRUCIAL que el DataFrame refleje las últimas operaciones (ej. eliminación de columnas)\n",
    "# Si tu script anterior ya dejó 'df_account_balances' en el estado deseado, puedes omitir esta recarga y transformación.\n",
    "# Sin embargo, para asegurar la reproducibilidad y que el CSV contenga el DataFrame limpio,\n",
    "# es buena práctica recargar y aplicar las transformaciones si este es un script independiente.\n",
    "\n",
    "print(\"Preparando el DataFrame 'accounting_account_balances' para exportación...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_account_balances = pd.read_sql('SELECT * FROM accounting_account_balances', engine)\n",
    "    \n",
    "    # Aplicar las eliminaciones de columnas que definimos previamente\n",
    "    columns_to_drop = ['created_at', 'updated_at', 'currency_id']\n",
    "    # Filtrar solo las columnas que realmente existen en el DataFrame para evitar errores si ya fueron eliminadas\n",
    "    existing_columns_to_drop = [col for col in columns_to_drop if col in df_account_balances.columns]\n",
    "    \n",
    "    if existing_columns_to_drop:\n",
    "        df_account_balances.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "        print(f\"Columnas {existing_columns_to_drop} eliminadas antes de exportar.\")\n",
    "    else:\n",
    "        print(\"Las columnas a eliminar ('created_at', 'updated_at', 'currency_id') no se encontraron o ya fueron eliminadas.\")\n",
    "\n",
    "    print(f\"DataFrame 'accounting_account_balances' listo para exportación. Filas: {df_account_balances.shape[0]}, Columnas: {df_account_balances.shape[1]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al preparar el DataFrame 'accounting_account_balances': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla.\n",
    "\n",
    "# --- Paso 2: Definir la ruta y el nombre del archivo CSV ---\n",
    "# Puedes ajustar la ruta donde quieres guardar el archivo.\n",
    "# 'os.getcwd()' te da el directorio de trabajo actual donde se está ejecutando el script.\n",
    "output_directory = os.getcwd() # Guarda en el mismo directorio del script\n",
    "csv_filename = 'accounting_account_balances_cleaned.csv'\n",
    "output_filepath = os.path.join(output_directory, csv_filename)\n",
    "\n",
    "# --- Paso 3: Exportar el DataFrame a un archivo CSV ---\n",
    "print(f\"\\nExportando el DataFrame a CSV: '{output_filepath}'...\")\n",
    "try:\n",
    "    df_account_balances.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "    print(\"¡DataFrame exportado a CSV exitosamente!\")\n",
    "    print(f\"Puedes encontrar el archivo en: {output_filepath}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al exportar el DataFrame a CSV: {e}\")\n",
    "\n",
    "print(\"\\nProceso de exportación a CSV completado.\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531295f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_account_balances' para análisis...\n",
      "Columnas ['created_at', 'updated_at', 'currency_id'] eliminadas para el análisis.\n",
      "DataFrame 'accounting_account_balances' listo para análisis. Filas: 4499, Columnas: 12\n",
      "\n",
      "--- Análisis Descriptivo de Columnas Numéricas ---\n",
      "               id         code  accounting_id  initial_balance  final_balance  \\\n",
      "count  4499.00000  4499.000000    4499.000000     4.499000e+03   4.499000e+03   \n",
      "mean   2250.00000     2.953210  117162.768615     1.811021e+08   8.990513e+07   \n",
      "std    1298.89376     1.615093  182842.279222     6.639901e+10   5.615416e+10   \n",
      "min       1.00000     1.000000       1.000000    -9.999962e+11  -9.999962e+11   \n",
      "25%    1125.50000     1.408010      24.000000     0.000000e+00   1.424200e+04   \n",
      "50%    2250.00000     2.501010    2502.000000     0.000000e+00   3.500000e+05   \n",
      "75%    3374.50000     5.000000  240401.000000     1.606800e+06   1.897309e+06   \n",
      "max    4499.00000     6.107990  610799.000000     9.999969e+11   9.999969e+11   \n",
      "\n",
      "       debit_movement  credit_movement  third_party_id    year        month  \n",
      "count    4.499000e+03     4.499000e+03     4499.000000  4499.0  4499.000000  \n",
      "mean    -1.463917e+09    -1.463408e+09       70.150700  2024.0     4.466993  \n",
      "std      5.393112e+10     5.393913e+10       65.007438     0.0     1.157442  \n",
      "min     -1.000000e+12    -1.000000e+12        1.000000  2024.0     2.000000  \n",
      "25%      0.000000e+00     0.000000e+00       18.000000  2024.0     4.000000  \n",
      "50%      1.450240e+05     1.000000e+05       42.000000  2024.0     5.000000  \n",
      "75%      9.714618e+05     1.026250e+06      107.000000  2024.0     5.000000  \n",
      "max      8.259942e+11     8.259942e+11      246.000000  2024.0     6.000000  \n",
      "\n",
      "--- Análisis de Distribución de Columnas Categóricas/Discretas ---\n",
      "\n",
      "Distribución de la columna 'name':\n",
      "                                      Count  Percentage\n",
      "name                                                   \n",
      "Pasivos                                 262    5.823516\n",
      "Servicios                               212    4.712158\n",
      "Intereses Sobre Cesantías               174    3.867526\n",
      "Prima De Servicios                      174    3.867526\n",
      "Activo                                  170    3.778617\n",
      "Gastos                                  168    3.734163\n",
      "De Administración Ordinarios            168    3.734163\n",
      "Personal                                163    3.623027\n",
      "Pasivos Por Beneficios A Empleados      162    3.600800\n",
      "Comercio Al Por Mayor Y Al Por Menor    157    3.489664\n",
      "... y 68 valores únicos más.\n",
      "\n",
      "Distribución de la columna 'third_party_type_id':\n",
      "                     Count  Percentage\n",
      "third_party_type_id                   \n",
      "Contact               2423   53.856413\n",
      "Employee              1256   27.917315\n",
      "PayrollProvider        820   18.226273\n",
      "\n",
      "Distribución de la columna 'year':\n",
      "      Count  Percentage\n",
      "year                   \n",
      "2024   4499       100.0\n",
      "\n",
      "Distribución de la columna 'month':\n",
      "       Count  Percentage\n",
      "month                   \n",
      "5       1734   38.541898\n",
      "6        857   19.048677\n",
      "3        849   18.870860\n",
      "4        810   18.004001\n",
      "2        249    5.534563\n",
      "\n",
      "Proceso de análisis descriptivo y de distribución completado para 'accounting_account_balances'.\n"
     ]
    }
   ],
   "source": [
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_account_balances' ---\n",
    "# Es CRUCIAL recargar el DataFrame y aplicar las transformaciones para asegurar\n",
    "# que estamos trabajando con la versión limpia de la tabla.\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_account_balances' para análisis...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_account_balances = pd.read_sql('SELECT * FROM accounting_account_balances', engine)\n",
    "    \n",
    "    # Aplicar las eliminaciones de columnas que definimos previamente\n",
    "    columns_to_drop = ['created_at', 'updated_at', 'currency_id']\n",
    "    existing_columns_to_drop = [col for col in columns_to_drop if col in df_account_balances.columns]\n",
    "    \n",
    "    if existing_columns_to_drop:\n",
    "        df_account_balances.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "        print(f\"Columnas {existing_columns_to_drop} eliminadas para el análisis.\")\n",
    "    else:\n",
    "        print(\"Las columnas ('created_at', 'updated_at', 'currency_id') no se encontraron o ya fueron eliminadas.\")\n",
    "\n",
    "    print(f\"DataFrame 'accounting_account_balances' listo para análisis. Filas: {df_account_balances.shape[0]}, Columnas: {df_account_balances.shape[1]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al preparar el DataFrame 'accounting_account_balances': {e}\")\n",
    "    raise # Relanzar la excepción si la carga o limpieza falla.\n",
    "\n",
    "# --- Paso 2: Análisis Descriptivo de Columnas Numéricas ---\n",
    "print(\"\\n--- Análisis Descriptivo de Columnas Numéricas ---\")\n",
    "# Seleccionar solo las columnas numéricas (enteros y flotantes)\n",
    "numeric_cols = df_account_balances.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if numeric_cols:\n",
    "    print(df_account_balances[numeric_cols].describe())\n",
    "else:\n",
    "    print(\"No se encontraron columnas numéricas para describir.\")\n",
    "\n",
    "# --- Paso 3: Análisis de Distribución de Columnas Categóricas/Discretas ---\n",
    "print(\"\\n--- Análisis de Distribución de Columnas Categóricas/Discretas ---\")\n",
    "\n",
    "# Identificar columnas categóricas o discretas con un número manejable de valores únicos\n",
    "# Excluimos las columnas que son IDs puros o que tienen demasiados valores únicos para un análisis de frecuencia\n",
    "# Consideramos columnas con <= 50 valores únicos como \"categóricas\" o \"discretas\" para este análisis.\n",
    "# Ajusta este umbral si tienes más o menos categorías esperadas.\n",
    "for col in df_account_balances.columns:\n",
    "    if col in numeric_cols and df_account_balances[col].nunique() > 50:\n",
    "        continue # Saltar IDs o columnas numéricas con muchos valores únicos\n",
    "    \n",
    "    if col in ['id', 'accounting_id', 'third_party_id']: # Saltar IDs específicos si no se quiere su frecuencia\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nDistribución de la columna '{col}':\")\n",
    "    # Mostrar los top N valores únicos y sus conteos/porcentajes\n",
    "    # El 10 es un valor arbitrario, puedes ajustarlo.\n",
    "    value_counts = df_account_balances[col].value_counts(dropna=False) # dropna=False para incluir nulos si los hubiera\n",
    "    value_percentages = df_account_balances[col].value_counts(dropna=False, normalize=True) * 100\n",
    "\n",
    "    distribution_df = pd.DataFrame({\n",
    "        'Count': value_counts,\n",
    "        'Percentage': value_percentages\n",
    "    })\n",
    "    \n",
    "    print(distribution_df.head(10)) # Mostrar los top 10 valores\n",
    "    \n",
    "    if df_account_balances[col].nunique() > 10:\n",
    "        print(f\"... y {df_account_balances[col].nunique() - 10} valores únicos más.\")\n",
    "\n",
    "\n",
    "print(\"\\nProceso de análisis descriptivo y de distribución completado para 'accounting_account_balances'.\")\n",
    "\n",
    "# Opcional: Si quieres guardar este DataFrame limpio y transformado para futuras operaciones\n",
    "# puedes usar df_account_balances.to_csv('accounting_account_balances_current_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22861f24",
   "metadata": {},
   "source": [
    "**ANALISIS TABLA accounting_account_balances**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4df6f2",
   "metadata": {},
   "source": [
    "1. id\n",
    "Tipo de Dato Esperado: bigint unsigned (Entero, clave primaria)\n",
    "Descripción: Identificador único para cada registro de balance de cuenta contable. Es la clave primaria de la tabla.\n",
    "\n",
    "2. code\n",
    "Tipo de Dato Esperado: double(16,15) (Numérico, código de cuenta)\n",
    "Descripción: Código de la cuenta contable al que se refiere este balance. Este código sigue la estructura del plan de cuentas (ej., 110505 para Caja General). Es vital para identificar la cuenta específica.\n",
    "Relevancia para KPIs: Nivel Alto.\n",
    "Fundamental para casi cualquier KPI financiero. Permite agrupar y filtrar balances por tipo de cuenta (Activo, Pasivo, Patrimonio, Ingresos, Gastos, Costos).\n",
    "\n",
    "\n",
    "3. accounting_id\n",
    "Tipo de Dato Esperado: bigint unsigned (Entero, clave foránea)\n",
    "Descripción: Identificador único de la cuenta contable maestro a la que pertenece este balance. Es probable que sea una clave foránea a la tabla accounting_accounts (donde id es la clave primaria).\n",
    "Relevancia para KPIs: Nivel Alto.\n",
    "Similar a code, pero es la clave numérica para vincular directamente con los metadatos de la cuenta contable (nombre, naturaleza, tipo, etc.) en la tabla accounting_accounts.\n",
    "Permite desglosar KPIs por la jerarquía del plan de cuentas (clase, grupo, cuenta, subcuenta).\n",
    "\n",
    "4. name\n",
    "Tipo de Dato Esperado: varchar(255) (Texto, nombre de la cuenta)\n",
    "Descripción: Nombre descriptivo de la cuenta contable (ej., \"Caja General\", \"Cuentas por Cobrar Clientes\").\n",
    "Relevancia para KPIs: Nivel Medio-Alto.\n",
    "No se usa en cálculos, pero es esencial para la legibilidad y la interpretación de los KPIs. Los usuarios finales no verán un code sino el name.\n",
    "Facilita la creación de informes y dashboards comprensibles.\n",
    "\n",
    "5. initial_balance\n",
    "Tipo de Dato Esperado: double(18,6) (Numérico, monetario)\n",
    "Descripción: Saldo de la cuenta contable al inicio del período (mes y año).\n",
    "Relevancia para KPIs: Nivel Alto.\n",
    "Fundamental para calcular el cambio en el saldo durante el período y para verificar la cuadratura contable.\n",
    "Usado en KPIs de flujos y evolución de cuentas.\n",
    "\n",
    "6. final_balance\n",
    "Tipo de Dato Esperado: double(18,6) (Numérico, monetario)\n",
    "Descripción: Saldo de la cuenta contable al final del período (mes y año).\n",
    "Relevancia para KPIs: Nivel Muy Alto.\n",
    "Directamente utilizado para la construcción del Balance General y el Estado de Resultados al final de cada período.\n",
    "La base para KPIs de liquidez (Cash), solvencia (Deuda), endeudamiento, patrimonio, activos totales, etc.\n",
    "\n",
    "7. debit_movement\n",
    "Tipo de Dato Esperado: double(18,6) (Numérico, monetario)\n",
    "Descripción: Suma total de los movimientos de débito (entradas o aumentos, según la naturaleza de la cuenta) para la cuenta contable durante el período.\n",
    "Relevancia para KPIs: Nivel Alto.\n",
    "Permite analizar el flujo bruto de actividad en una cuenta.\n",
    "Junto con credit_movement, es crucial para verificar la ecuación contable (SaldoInicial+Débitos −Créditos =SaldoFinal) y para el análisis de la actividad transaccional.\n",
    "Puede usarse para KPIs de volumen de transacciones o actividad por cuenta.\n",
    "\n",
    "8. credit_movement\n",
    "Tipo de Dato Esperado: double(18,6) (Numérico, monetario)\n",
    "Descripción: Suma total de los movimientos de crédito (salidas o disminuciones, según la naturaleza de la cuenta) para la cuenta contable durante el período.\n",
    "Relevancia para KPIs: Nivel Alto.\n",
    "Similar a debit_movement, esencial para el análisis del flujo bruto y la validación contable.\n",
    "Utilizado para KPIs de volumen de transacciones.\n",
    "\n",
    "9. third_party_type_id\n",
    "Tipo de Dato Esperado: varchar(50) (Texto, tipo de tercero)\n",
    "Descripción: Identificador del tipo de tercero asociado a la cuenta (ej., \"Cliente\", \"Proveedor\", \"Empleado\", etc.).\n",
    "Relevancia para KPIs: Nivel Medio-Alto.\n",
    "Permite desglosar balances por tipo de contraparte. Por ejemplo, \"cuentas por cobrar a clientes\" vs \"cuentas por cobrar a empleados\".\n",
    "Útil para análisis de riesgo de clientes/proveedores, antigüedad de cartera segmentada por tipo de tercero.\n",
    "\n",
    "10. third_party_id\n",
    "Tipo de Dato Esperado: bigint unsigned (Entero, ID de tercero)\n",
    "Descripción: Identificador único del tercero específico (persona o empresa) asociado a la cuenta. Es probable que sea una clave foránea a una tabla de \"terceros\".\n",
    "Relevancia para KPIs: Nivel Alto.\n",
    "Fundamental para análisis a nivel de cliente/proveedor individual.\n",
    "KPIs: Concentración de clientes/proveedores, volumen de negocios por tercero, antigüedad de cartera por tercero, riesgo de impago por tercero.\n",
    "\n",
    "11. year\n",
    "Tipo de Dato Esperado: int (Entero)\n",
    "Descripción: Año al que corresponde este balance de cuenta.\n",
    "Relevancia para KPIs: Nivel Muy Alto.\n",
    "Esencial para cualquier análisis de tendencia, comparativas anuales, y para la generación de estados financieros por año.\n",
    "Permite calcular KPIs anuales como el crecimiento de ingresos, evolución de gastos, etc.\n",
    "\n",
    "12. month\n",
    "Tipo de Dato Esperado: int (Entero)\n",
    "Descripción: Mes al que corresponde este balance de cuenta (1 para enero, 12 para diciembre).\n",
    "Relevancia para KPIs: Nivel Muy Alto.\n",
    "Esencial para análisis de tendencia mensual, comparativas mensuales, estacionalidad, y para la generación de estados financieros mensuales/trimestrales.\n",
    "Permite KPIs de liquidez a corto plazo, tendencias de ventas mensuales, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22586c9e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b602a50",
   "metadata": {},
   "source": [
    "***2. Tabla accounting_accounts***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6db077",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_accounts':\n",
      "  - id (bigint unsigned)\n",
      "  - name (varchar(250))\n",
      "  - is_class (tinyint(1))\n",
      "  - is_group (tinyint(1))\n",
      "  - is_account (tinyint(1))\n",
      "  - is_subaccount (tinyint(1))\n",
      "  - is_auxiliary (tinyint(1))\n",
      "  - is_subauxiliary (tinyint(1))\n",
      "  - niif (tinyint(1))\n",
      "  - cash_flow (tinyint(1))\n",
      "  - exogenous (tinyint(1))\n",
      "  - base_value (tinyint(1))\n",
      "  - nature (varchar(1))\n",
      "  - term (tinyint(1))\n",
      "  - favorite (tinyint(1))\n",
      "  - status (tinyint(1))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_accounts;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_accounts':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9bdeb",
   "metadata": {},
   "source": [
    "Detección de Columnas Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67456435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_accounts'...\n",
      "Tabla 'accounting_accounts' cargada exitosamente. Filas: 2125, Columnas: 18\n",
      "\n",
      "Identificando columnas con valores constantes en 'accounting_accounts'...\n",
      "\n",
      "Columnas con valores constantes identificadas en 'accounting_accounts':\n",
      "  - 'is_subauxiliary': Valor único = 0\n",
      "  - 'cash_flow': Valor único = 0\n",
      "  - 'exogenous': Valor único = 0\n",
      "  - 'base_value': Valor único = 0\n",
      "  - 'term': Valor único = 0\n",
      "  - 'favorite': Valor único = 0\n",
      "  - 'status': Valor único = 1\n",
      "\n",
      "Proceso de identificación de columnas constantes completado para 'accounting_accounts'.\n",
      "\n",
      "Primeras 5 filas del DataFrame 'accounting_accounts':\n",
      "   id        name  is_class  is_group  is_account  is_subaccount  \\\n",
      "0   1      Activo         1         0           0              0   \n",
      "1   2     Pasivos         1         0           0              0   \n",
      "2   3  Patrimonio         1         0           0              0   \n",
      "3   4    Ingresos         1         0           0              0   \n",
      "4   5      Gastos         1         0           0              0   \n",
      "\n",
      "   is_auxiliary  is_subauxiliary  niif  cash_flow  exogenous  base_value  \\\n",
      "0             0                0     1          0          0           0   \n",
      "1             0                0     1          0          0           0   \n",
      "2             0                0     1          0          0           0   \n",
      "3             0                0     1          0          0           0   \n",
      "4             0                0     1          0          0           0   \n",
      "\n",
      "  nature  term  favorite  status          created_at          updated_at  \n",
      "0      D     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "1      C     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "2      C     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "3      C     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n",
      "4      D     0         0       1 2024-03-27 12:07:39 2024-03-27 12:07:39  \n"
     ]
    }
   ],
   "source": [
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_accounts' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_accounts'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_accounts = pd.read_sql('SELECT * FROM accounting_accounts', engine)\n",
    "    print(f\"Tabla 'accounting_accounts' cargada exitosamente. Filas: {df_accounting_accounts.shape[0]}, Columnas: {df_accounting_accounts.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_accounts': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Identificar columnas con valores constantes ---\n",
    "print(\"\\nIdentificando columnas con valores constantes en 'accounting_accounts'...\")\n",
    "\n",
    "constant_columns = []\n",
    "for col in df_accounting_accounts.columns:\n",
    "    # `nunique()` cuenta el número de valores únicos en una columna.\n",
    "    # Si es 1, significa que todos los valores son el mismo (constante).\n",
    "    if df_accounting_accounts[col].nunique() == 1:\n",
    "        constant_columns.append(col)\n",
    "\n",
    "if constant_columns:\n",
    "    print(f\"\\nColumnas con valores constantes identificadas en 'accounting_accounts':\")\n",
    "    for col in constant_columns:\n",
    "        print(f\"  - '{col}': Valor único = {df_accounting_accounts[col].iloc[0]}\") # Muestra el valor constante\n",
    "else:\n",
    "    print(\"No se encontraron columnas con valores constantes en la tabla 'accounting_accounts'.\")\n",
    "\n",
    "print(\"\\nProceso de identificación de columnas constantes completado para 'accounting_accounts'.\")\n",
    "\n",
    "# --- Opcional: Mostrar las primeras filas del DataFrame para referencia ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'accounting_accounts':\")\n",
    "print(df_accounting_accounts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55d713",
   "metadata": {},
   "source": [
    "Eliminación de Columna Constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608cd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- Paso 1: Conectarse a la base de datos y cargar la tabla \\'accounting_accounts\\' ---\\nprint(\"Conectando a la base de datos y cargando la tabla \\'accounting_accounts\\'...\")\\ntry:\\n    engine = get_engine()\\n    df_accounting_accounts = pd.read_sql(\\'SELECT * FROM accounting_accounts\\', engine)\\n    print(f\"Tabla \\'accounting_accounts\\' cargada exitosamente. Filas: {df_accounting_accounts.shape[0]}, Columnas: {df_accounting_accounts.shape[1]}\")\\nexcept Exception as e:\\n    print(f\"Error al cargar la tabla \\'accounting_accounts\\': {e}\")\\n    raise # Relanzar la excepción para detener la ejecución si falla la carga.\\n\\n# --- Paso 2: Definir y eliminar las columnas constantes ---\\nprint(\"\\nEliminando columnas constantes de \\'accounting_accounts\\'...\")\\n\\n# Lista de columnas identificadas como constantes\\ncolumns_to_drop_constant = [\\n    \\'is_subauxiliary\\',\\n    \\'cash_flow\\',\\n    \\'exogenous\\',\\n    \\'base_value\\',\\n    \\'term\\',\\n    \\'favorite\\',\\n    \\'status\\'\\n]\\n\\n# Es buena práctica verificar que las columnas existen antes de intentar eliminarlas\\nexisting_columns_to_drop = [col for col in columns_to_drop_constant if col in df_accounting_accounts.columns]\\n\\nif existing_columns_to_drop:\\n    df_accounting_accounts.drop(columns=existing_columns_to_drop, inplace=True)\\n    print(f\"Columnas {existing_columns_to_drop} eliminadas exitosamente.\")\\nelse:\\n    print(\"Ninguna de las columnas constantes a eliminar se encontró en el DataFrame o ya fueron eliminadas.\")\\n\\n# --- Paso 3: Verificar las columnas restantes ---\\nprint(f\"\\nColumnas restantes en el DataFrame \\'accounting_accounts\\':\")\\nprint(df_accounting_accounts.columns.tolist())\\n\\n# --- Paso 4: Mostrar las primeras filas del DataFrame modificado ---\\nprint(\"\\nPrimeras 5 filas del DataFrame \\'accounting_accounts\\' después de la eliminación:\")\\nprint(df_accounting_accounts.head())\\n\\nprint(\"\\nProceso de eliminación de columnas constantes completado para \\'accounting_accounts\\'.\") '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_accounts' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_accounts'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_accounts = pd.read_sql('SELECT * FROM accounting_accounts', engine)\n",
    "    print(f\"Tabla 'accounting_accounts' cargada exitosamente. Filas: {df_accounting_accounts.shape[0]}, Columnas: {df_accounting_accounts.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_accounts': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Definir y eliminar las columnas constantes ---\n",
    "print(\"\\nEliminando columnas constantes de 'accounting_accounts'...\")\n",
    "\n",
    "# Lista de columnas identificadas como constantes\n",
    "columns_to_drop_constant = [\n",
    "    'is_subauxiliary',\n",
    "    'cash_flow',\n",
    "    'exogenous',\n",
    "    'base_value',\n",
    "    'term',\n",
    "    'favorite',\n",
    "    'status'\n",
    "]\n",
    "\n",
    "# Es buena práctica verificar que las columnas existen antes de intentar eliminarlas\n",
    "existing_columns_to_drop = [col for col in columns_to_drop_constant if col in df_accounting_accounts.columns]\n",
    "\n",
    "if existing_columns_to_drop:\n",
    "    df_accounting_accounts.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "    print(f\"Columnas {existing_columns_to_drop} eliminadas exitosamente.\")\n",
    "else:\n",
    "    print(\"Ninguna de las columnas constantes a eliminar se encontró en el DataFrame o ya fueron eliminadas.\")\n",
    "\n",
    "# --- Paso 3: Verificar las columnas restantes ---\n",
    "print(f\"\\nColumnas restantes en el DataFrame 'accounting_accounts':\")\n",
    "print(df_accounting_accounts.columns.tolist())\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas del DataFrame modificado ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'accounting_accounts' después de la eliminación:\")\n",
    "print(df_accounting_accounts.head())\n",
    "\n",
    "print(\"\\nProceso de eliminación de columnas constantes completado para 'accounting_accounts'.\") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d83f61d",
   "metadata": {},
   "source": [
    "**ANALISIS accounting_accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82302122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bloque 3.3: Analizando distribución de columnas en 'accounting_accounts' ---\n",
      "\n",
      "--- Estadísticas Descriptivas para Columnas Numéricas ---\n",
      "Todas las columnas numéricas:\n",
      "                 id     is_class     is_group   is_account  is_subaccount  \\\n",
      "count  2.125000e+03  2125.000000  2125.000000  2125.000000    2125.000000   \n",
      "mean   2.872738e+05     0.003765     0.019294     0.155765       0.820706   \n",
      "std    3.114951e+05     0.061256     0.137589     0.362717       0.383689   \n",
      "min    1.000000e+00     0.000000     0.000000     0.000000       0.000000   \n",
      "25%    1.307050e+05     0.000000     0.000000     0.000000       1.000000   \n",
      "50%    2.311160e+05     0.000000     0.000000     0.000000       1.000000   \n",
      "75%    5.102020e+05     0.000000     0.000000     0.000000       1.000000   \n",
      "max    1.102010e+07     1.000000     1.000000     1.000000       1.000000   \n",
      "\n",
      "       is_auxiliary  is_subauxiliary         niif  cash_flow  exogenous  \\\n",
      "count   2125.000000           2125.0  2125.000000     2125.0     2125.0   \n",
      "mean       0.000471              0.0     0.999529        0.0        0.0   \n",
      "std        0.021693              0.0     0.021693        0.0        0.0   \n",
      "min        0.000000              0.0     0.000000        0.0        0.0   \n",
      "25%        0.000000              0.0     1.000000        0.0        0.0   \n",
      "50%        0.000000              0.0     1.000000        0.0        0.0   \n",
      "75%        0.000000              0.0     1.000000        0.0        0.0   \n",
      "max        1.000000              0.0     1.000000        0.0        0.0   \n",
      "\n",
      "       base_value    term  favorite  status  \n",
      "count      2125.0  2125.0    2125.0  2125.0  \n",
      "mean          0.0     0.0       0.0     1.0  \n",
      "std           0.0     0.0       0.0     0.0  \n",
      "min           0.0     0.0       0.0     1.0  \n",
      "25%           0.0     0.0       0.0     1.0  \n",
      "50%           0.0     0.0       0.0     1.0  \n",
      "75%           0.0     0.0       0.0     1.0  \n",
      "max           0.0     0.0       0.0     1.0  \n",
      "\n",
      "Estadísticas Descriptivas para Columnas Numéricas con Variabilidad (excluyendo IDs y constantes):\n",
      "          is_class     is_group   is_account  is_subaccount  is_auxiliary  \\\n",
      "count  2125.000000  2125.000000  2125.000000    2125.000000   2125.000000   \n",
      "mean      0.003765     0.019294     0.155765       0.820706      0.000471   \n",
      "std       0.061256     0.137589     0.362717       0.383689      0.021693   \n",
      "min       0.000000     0.000000     0.000000       0.000000      0.000000   \n",
      "25%       0.000000     0.000000     0.000000       1.000000      0.000000   \n",
      "50%       0.000000     0.000000     0.000000       1.000000      0.000000   \n",
      "75%       0.000000     0.000000     0.000000       1.000000      0.000000   \n",
      "max       1.000000     1.000000     1.000000       1.000000      1.000000   \n",
      "\n",
      "              niif  \n",
      "count  2125.000000  \n",
      "mean      0.999529  \n",
      "std       0.021693  \n",
      "min       0.000000  \n",
      "25%       1.000000  \n",
      "50%       1.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n",
      "\n",
      "--- Análisis de Distribución para Columnas Categóricas/Discretas ---\n",
      "\n",
      "Distribución de la columna 'name':\n",
      "Total de nombres de cuentas únicos: 1205\n",
      "Mostrando solo los primeros 10 por brevedad para 'name'.\n",
      "                                         Count  Percentage\n",
      "name                                                      \n",
      "Deterioro                                   45    2.117647\n",
      "Revaluación                                 22    1.035294\n",
      "Depreciación Acumulada                      15    0.705882\n",
      "Flota Y Equipo Férreo                       13    0.611765\n",
      "Flota Y Equipo Aéreo                        13    0.611765\n",
      "Devoluciones, Rebajas Y Descuentos (Db)     13    0.611765\n",
      "Comisiones                                  13    0.611765\n",
      "Maquinaria Y Equipo                         12    0.564706\n",
      "Equipo De Oficina                           12    0.564706\n",
      "Equipo De Hoteles Y Restaurantes            12    0.564706\n",
      "\n",
      "Distribución de la columna 'nature':\n",
      "        Count  Percentage\n",
      "nature                   \n",
      "D        1323   62.258824\n",
      "C         802   37.741176\n",
      "\n",
      "Distribución de la columna 'is_class':\n",
      "          Count  Percentage\n",
      "is_class                   \n",
      "0          2117   99.623529\n",
      "1             8    0.376471\n",
      "\n",
      "Distribución de la columna 'is_group':\n",
      "          Count  Percentage\n",
      "is_group                   \n",
      "0          2084   98.070588\n",
      "1            41    1.929412\n",
      "\n",
      "Distribución de la columna 'is_account':\n",
      "            Count  Percentage\n",
      "is_account                   \n",
      "0            1794   84.423529\n",
      "1             331   15.576471\n",
      "\n",
      "Distribución de la columna 'is_subaccount':\n",
      "               Count  Percentage\n",
      "is_subaccount                   \n",
      "1               1744   82.070588\n",
      "0                381   17.929412\n",
      "\n",
      "Distribución de la columna 'is_auxiliary':\n",
      "              Count  Percentage\n",
      "is_auxiliary                   \n",
      "0              2124   99.952941\n",
      "1                 1    0.047059\n",
      "\n",
      "Distribución de la columna 'niif':\n",
      "      Count  Percentage\n",
      "niif                   \n",
      "1      2124   99.952941\n",
      "0         1    0.047059\n",
      "\n",
      "--- Bloque 3.3 Completado ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # Necesario para np.number\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Asumo que 'engine' y 'df_accounting_accounts' ya fueron establecidos\n",
    "# en los bloques anteriores y están disponibles.\n",
    "from db_connection import get_engine # Asegúrate de que esta importación esté presente si es necesario.\n",
    "\n",
    "print(\"--- Bloque 3.3: Analizando distribución de columnas en 'accounting_accounts' ---\")\n",
    "\n",
    "# En un flujo de script secuencial, df_accounting_accounts ya estaría cargado.\n",
    "# Si estás ejecutando este bloque de forma independiente, recarga el DataFrame:\n",
    "if 'df_accounting_accounts' not in locals() or df_accounting_accounts.empty:\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        df_accounting_accounts = pd.read_sql('SELECT * FROM accounting_accounts', engine)\n",
    "        print(\"DataFrame 'accounting_accounts' recargado para el Bloque 3.3.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al recargar el DataFrame para el Bloque 3.3: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Análisis Descriptivo de Columnas Numéricas ---\n",
    "print(\"\\n--- Estadísticas Descriptivas para Columnas Numéricas ---\")\n",
    "numeric_cols = df_accounting_accounts.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "if numeric_cols:\n",
    "    # Excluimos 'id' de la descripción numérica si es un simple identificador sin significado estadístico\n",
    "    # Sin embargo, para booleanos (0/1) que son int64, describe() es útil para ver su distribución.\n",
    "    # Aquí vamos a describir todas las numéricas y luego enfocarnos en las no booleanas para un análisis más profundo.\n",
    "    \n",
    "    # Columnas numéricas que NO son IDs puros o flags booleanas constantes (las identificadas en 3.2)\n",
    "    # Revisa si hay alguna columna numérica que no sea un flag constante 0/1.\n",
    "    # Del output anterior, todas nuestras 'int64' excepto 'id' y 'niif' parecen ser flags.\n",
    "    # 'id' y 'niif' también son int64.\n",
    "    \n",
    "    # Listamos todas las columnas numéricas\n",
    "    print(\"Todas las columnas numéricas:\")\n",
    "    print(df_accounting_accounts[numeric_cols].describe())\n",
    "\n",
    "    # Consideremos específicamente las columnas numéricas que *podrían* tener rangos y variabilidad\n",
    "    # Excluyendo 'id' y las que ya sabemos que son constantes de 0/1.\n",
    "    cols_for_deeper_numeric_analysis = []\n",
    "    \n",
    "    # Recargamos la lista de constantes para este bloque si es necesario (para un script independiente)\n",
    "    constant_columns = []\n",
    "    for col in df_accounting_accounts.columns:\n",
    "        if df_accounting_accounts[col].nunique() == 1:\n",
    "            constant_columns.append(col)\n",
    "            \n",
    "    for col in numeric_cols:\n",
    "        if col not in constant_columns and col != 'id': # Excluir ID y constantes\n",
    "            cols_for_deeper_numeric_analysis.append(col)\n",
    "\n",
    "    if cols_for_deeper_numeric_analysis:\n",
    "        print(\"\\nEstadísticas Descriptivas para Columnas Numéricas con Variabilidad (excluyendo IDs y constantes):\")\n",
    "        print(df_accounting_accounts[cols_for_deeper_numeric_analysis].describe())\n",
    "    else:\n",
    "        print(\"\\nNo se encontraron columnas numéricas con variabilidad significativa (más allá de IDs o constantes) para un análisis descriptivo más profundo.\")\n",
    "\n",
    "else:\n",
    "    print(\"No se encontraron columnas numéricas en el DataFrame.\")\n",
    "\n",
    "\n",
    "# --- Análisis de Distribución de Columnas Categóricas/Discretas ---\n",
    "print(\"\\n--- Análisis de Distribución para Columnas Categóricas/Discretas ---\")\n",
    "\n",
    "# Seleccionar columnas de tipo 'object' (cadenas) y también 'int64' que no sean IDs\n",
    "# y que no sean las columnas constantes que ya identificamos.\n",
    "categorical_cols = df_accounting_accounts.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Incluir las columnas numéricas que son flags o tienen pocos valores únicos y no son constantes\n",
    "# Por ejemplo, 'is_class', 'is_group', 'is_account', 'is_subaccount', 'is_auxiliary', 'niif'\n",
    "# Aunque 'niif' es int64, tiene 2125 non-null y su valor de '1' del head sugiere que podría ser constante,\n",
    "# pero su comportamiento de 'flag' la hace relevante para un value_counts.\n",
    "# Las columnas 'is_subauxiliary', 'cash_flow', 'exogenous', 'base_value', 'term', 'favorite', 'status'\n",
    "# ya sabemos que son constantes, así que no las incluimos en este análisis de distribución detallado.\n",
    "\n",
    "# Agregamos las columnas que parecen flags (int64 con pocos valores únicos)\n",
    "potential_flag_cols = [\n",
    "    'is_class', 'is_group', 'is_account', 'is_subaccount', 'is_auxiliary', 'niif'\n",
    "]\n",
    "\n",
    "# Combinamos y filtramos para no duplicar ni incluir constantes ya conocidas\n",
    "cols_for_category_analysis = []\n",
    "cols_for_category_analysis.extend(categorical_cols) # 'name', 'nature'\n",
    "\n",
    "for col in potential_flag_cols:\n",
    "    if col not in constant_columns and col not in cols_for_category_analysis:\n",
    "        cols_for_category_analysis.append(col)\n",
    "\n",
    "if cols_for_category_analysis:\n",
    "    for col in cols_for_category_analysis:\n",
    "        print(f\"\\nDistribución de la columna '{col}':\")\n",
    "        # Mostrar los top N valores únicos y sus conteos/porcentajes\n",
    "        # dropna=False para incluir nulos si los hubiera (aunque ya sabemos que no hay en esta tabla)\n",
    "        value_counts = df_accounting_accounts[col].value_counts(dropna=False)\n",
    "        value_percentages = df_accounting_accounts[col].value_counts(dropna=False, normalize=True) * 100\n",
    "\n",
    "        distribution_df = pd.DataFrame({\n",
    "            'Count': value_counts,\n",
    "            'Percentage': value_percentages\n",
    "        })\n",
    "        \n",
    "        # Ajustamos para mostrar más si hay muchas categorías o solo las relevantes\n",
    "        if col == 'name': # Si 'name' es muy variado, solo mostramos el conteo total\n",
    "            print(f\"Total de nombres de cuentas únicos: {df_accounting_accounts['name'].nunique()}\")\n",
    "            print(\"Mostrando solo los primeros 10 por brevedad para 'name'.\")\n",
    "            print(distribution_df.head(10))\n",
    "        else: # Para las demás, mostramos hasta 20 o todas si son menos\n",
    "            print(distribution_df.head(20) if distribution_df.shape[0] > 20 else distribution_df)\n",
    "else:\n",
    "    print(\"No se encontraron columnas categóricas o discretas con variabilidad para analizar.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Bloque 3.3 Completado ---\")\n",
    "\n",
    "# df_accounting_accounts permanece sin cambios en este bloque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc51082",
   "metadata": {},
   "source": [
    "Estadísticas Descriptivas para Columnas Numéricas:\n",
    "\n",
    "id: Es un identificador único, como se espera. El rango (min 1, max 1.1e+07) es amplio, lo cual es normal para IDs. No se usa en cálculos de KPIs directamente.\n",
    "Columnas \"Flag\" (is_class, is_group, is_account, is_subaccount, is_auxiliary, niif):\n",
    "Todas estas columnas son binarias (0 o 1), lo cual es consistente con su naturaleza de \"flags\" (indicadores booleanos).\n",
    "Sus mean (media) reflejan la proporción de 1s en la columna. Por ejemplo:\n",
    "is_class: 0.37% son clases (valor 1), el resto (0) no lo son.\n",
    "is_group: 1.93% son grupos.\n",
    "is_account: 15.58% son cuentas.\n",
    "is_subaccount: ¡82.07% son subcuentas! Esto indica que la mayoría de los registros en esta tabla son a nivel de subcuenta, lo cual es típico en un plan de cuentas detallado.\n",
    "is_auxiliary: Solo un 0.047% son auxiliares.\n",
    "niif: Un 99.95% están bajo NIIF (valor 1), con solo un registro en 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15670a",
   "metadata": {},
   "source": [
    "Columnas Constantes: Confirmado que is_subauxiliary, cash_flow, exogenous, base_value, term, favorite, status son constantes. Estas son fuertes candidatas para eliminación.\n",
    "Columnas Casi Constantes: is_auxiliary y niif tienen muy poca variabilidad (un solo valor diferente). Podrían eliminarse si su presencia no es crítica y se busca la máxima simplicidad. Mi recomendación inicial sería eliminarlas también, ya que casi no aportan información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207678c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En un flujo de script secuencial, df_accounting_accounts ya estaría cargado.\n",
    "# Si estás ejecutando este bloque de forma independiente, recarga el DataFrame:\n",
    "if 'df_accounting_accounts' not in locals() or df_accounting_accounts.empty:\n",
    "    try:\n",
    "        engine = get_engine()\n",
    "        df_accounting_accounts = pd.read_sql('SELECT * FROM accounting_accounts', engine)\n",
    "        print(\"DataFrame 'accounting_accounts' recargado para el Bloque 3.4.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al recargar el DataFrame para el Bloque 3.4: {e}\")\n",
    "        raise\n",
    "\n",
    "# Columnas identificadas como constantes o casi constantes:\n",
    "columns_to_drop = [\n",
    "    'is_subauxiliary', # Constante (0)\n",
    "    'cash_flow',       # Constante (0)\n",
    "    'exogenous',       # Constante (0)\n",
    "    'base_value',      # Constante (0)\n",
    "    'term',            # Constante (0)\n",
    "    'favorite',        # Constante (0)\n",
    "    'status',          # Constante (1)\n",
    "    'is_auxiliary',    # Casi constante (99.95% en 0)\n",
    "    'niif',            # Casi constante (99.95% en 1)\n",
    "    'created_at',      # Metadato de fecha/hora de creación\n",
    "    'updated_at'       # Metadato de fecha/hora de última actualización\n",
    "]\n",
    "\n",
    "# Filtramos las columnas que realmente existen en el DataFrame antes de intentar eliminarlas\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in df_accounting_accounts.columns]\n",
    "\n",
    "if existing_columns_to_drop:\n",
    "    df_accounting_accounts.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "    print(f\"Columnas eliminadas exitosamente: {existing_columns_to_drop}\")\n",
    "else:\n",
    "    print(\"Ninguna de las columnas especificadas para eliminar se encontró en el DataFrame o ya fueron eliminadas.\")\n",
    "\n",
    "# Mostrar las dimensiones del DataFrame después de la eliminación\n",
    "print(f\"\\nNuevas dimensiones de 'accounting_accounts': {df_accounting_accounts.shape[0]} filas, {df_accounting_accounts.shape[1]} columnas.\")\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame modificado para verificar\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'accounting_accounts' después de la eliminación de columnas:\")\n",
    "print(df_accounting_accounts.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8647dad6",
   "metadata": {},
   "source": [
    "# 📊 Análisis Detallado de Columnas en `accounting_accounts` 📊\n",
    "\n",
    "Este análisis se basa en el output original del Bloque 3.1 y 3.3, previo a cualquier eliminación de columnas, para justificar y documentar las decisiones de limpieza.\n",
    "\n",
    "---\n",
    "\n",
    "## **Contexto General de la Tabla `accounting_accounts`**\n",
    "\n",
    "Esta tabla representa el **Plan de Cuentas Contable** de una empresa. Cada fila describe una cuenta contable específica con sus características y atributos. La **jerarquía contable** (Clase, Grupo, Cuenta, Subcuenta, Auxiliar, Subauxiliar) es fundamental en este tipo de tablas.\n",
    "\n",
    "En contabilidad, un plan de cuentas es una lista estructurada de todas las cuentas que una organización utiliza para registrar sus transacciones financieras. La estructura jerárquica permite un nivel de detalle creciente, desde categorías generales (Clase) hasta cuentas muy específicas (Subauxiliar).\n",
    "\n",
    "---\n",
    "\n",
    "## **Columnas Presentes en el DataFrame Original (Antes de la Limpieza):**\n",
    "\n",
    "### **Columnas Conservadas (Relevantes para Análisis/Modelado):**\n",
    "\n",
    "* **`id`**\n",
    "    * **Tipo de Dato:** `int64`\n",
    "    * **Descripción:** Identificador único para cada cuenta contable (clave primaria).\n",
    "    * **Relevancia:** Esencial para la integridad de la base de datos y la vinculación con otras tablas (ej., `accounting_account_balances`).\n",
    "    * **Decisión:** **Conservada.**\n",
    "\n",
    "* **`name`**\n",
    "    * **Tipo de Dato:** `object` (cadena de texto)\n",
    "    * **Descripción:** Nombre descriptivo de la cuenta contable (ej., \"Activo\", \"Caja General\").\n",
    "    * **Relevancia:** Altamente relevante. Fundamental para la interpretación de cualquier análisis y para la comprensión por parte del usuario. Hay 1205 nombres únicos.\n",
    "    * **Decisión:** **Conservada.**\n",
    "\n",
    "* **`is_class`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta es una \"Clase\" contable (ej., \"Activo\", \"Pasivo\").\n",
    "    * **Relevancia:** Relevante. Permite categorizar al nivel más alto de la jerarquía contable, crucial para estados financieros. La media (0.003765) indica solo 8 de 2125 son clases, lo cual es correcto.\n",
    "    * **Decisión:** **Conservada.**\n",
    "\n",
    "* **`is_group`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta es un \"Grupo\" contable (ej., \"Disponible\", \"Inversiones\").\n",
    "    * **Relevancia:** Relevante. Permite agrupaciones importantes dentro de las clases. La media (0.019294) indica 41 de 2125 son grupos.\n",
    "    * **Decisión:** **Conservada.**\n",
    "\n",
    "* **`is_account`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta es una \"Cuenta\" contable (ej., \"Caja\", \"Bancos\").\n",
    "    * **Relevancia:** Relevante. Nivel de detalle intermedio, útil para análisis por tipo de cuenta. La media (0.155765) indica 331 de 2125 son cuentas.\n",
    "    * **Decisión:** **Conservada.**\n",
    "\n",
    "* **`is_subaccount`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta es una \"Subcuenta\" contable (ej., \"Caja General\", \"Caja Menor\").\n",
    "    * **Relevancia:** Muy relevante. La mayoría de los registros (82.07%) son subcuentas, nivel donde se registran la mayoría de las transacciones, fundamental para análisis granular.\n",
    "    * **Decisión:** **Conservada.**\n",
    "\n",
    "* **`nature`**\n",
    "    * **Tipo de Dato:** `object` (cadena de texto)\n",
    "    * **Descripción:** Indica la naturaleza de la cuenta: **D** (Débito) o **C** (Crédito).\n",
    "    * **Relevancia:** Altamente relevante. Fundamental para entender el comportamiento de los saldos (aumenta con débitos/créditos) y para la validación contable. La distribución (62.26% D, 37.74% C) es esperada.\n",
    "    * **Decisión:** **Conservada.**\n",
    "\n",
    "### **Columnas Eliminadas (Baja o Nula Relevancia para Análisis/Modelado):**\n",
    "\n",
    "* **`is_auxiliary`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta es una \"Auxiliar\" contable.\n",
    "    * **Relevancia:** Baja. El 99.95% de los valores son 0 (solo 1 registro es 1). Aporta variabilidad insignificante.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`is_subauxiliary`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta es una \"Subauxiliar\" contable.\n",
    "    * **Relevancia:** Nula. El 100% de los valores son 0. Es una columna constante.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`niif`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta aplica bajo Normas Internacionales de Información Financiera (NIIF).\n",
    "    * **Relevancia:** Baja. El 99.95% de los valores son 1 (solo 1 registro es 0). No permite una diferenciación útil.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`cash_flow`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta está relacionada con el flujo de efectivo.\n",
    "    * **Relevancia:** Nula. El 100% de los valores son 0. Es una columna constante.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`exogenous`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indica si la cuenta es \"exógena\" (relacionada con informes fiscales o regulatorios).\n",
    "    * **Relevancia:** Nula. El 100% de los valores son 0. Es una columna constante.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`base_value`**\n",
    "    * **Tipo de Dato:** `int64`\n",
    "    * **Descripción:** Posiblemente un valor base o flag para cálculos específicos.\n",
    "    * **Relevancia:** Nula. El 100% de los valores son 0. Es una columna constante.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`term`**\n",
    "    * **Tipo de Dato:** `int64`\n",
    "    * **Descripción:** Posiblemente indica el término de la cuenta (corto/largo plazo).\n",
    "    * **Relevancia:** Nula. El 100% de los valores son 0. Es una columna constante.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`favorite`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Indicador para marcar cuentas \"favoritas\" en el sistema.\n",
    "    * **Relevancia:** Nula. El 100% de los valores son 0. Es una característica interna del sistema, no relevante para el análisis.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`status`**\n",
    "    * **Tipo de Dato:** `int64` (flag booleana)\n",
    "    * **Descripción:** Posiblemente el estado de la cuenta (activa/inactiva).\n",
    "    * **Relevancia:** Nula. El 100% de los valores son 1. Es una columna constante; no proporciona información diferencial.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`created_at`**\n",
    "    * **Tipo de Dato:** `datetime64[ns]`\n",
    "    * **Descripción:** Fecha y hora de creación del registro.\n",
    "    * **Relevancia:** Baja. Metadato de auditoría. No contribuye directamente a los KPIs financieros o modelos de ML.\n",
    "    * **Decisión:** **Eliminada.**\n",
    "\n",
    "* **`updated_at`**\n",
    "    * **Tipo de Dato:** `datetime64[ns]`\n",
    "    * **Descripción:** Fecha y hora de la última actualización del registro.\n",
    "    * **Relevancia:** Baja. Similar a `created_at`, es un metadato.\n",
    "    * **Decisión:** **Eliminada.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7b08e",
   "metadata": {},
   "source": [
    "***3. Tabla accounting_movements***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69120ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocurrió un error: name 'get_connection' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_movements;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_movements':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6951229",
   "metadata": {},
   "source": [
    "#Se identifica que hay datos faltantes en las columnas: o\treferences_document_id: 6019 nulos (85.74%)\n",
    "o\titem_id: 5511 nulos (78.50%)\n",
    "o\titem_type: 5511 nulos (78.50%)\n",
    "o\tdocument: 4510 nulos (64.25%)\n",
    "o\tpayroll_employee_reference_id: 2510 nulos (35.75%)\n",
    "\n",
    "-> Se identifica que las columnas item_type, item_id y references_document_id refieren a lo mismo, por lo cual, solo se llenaba una de las 3, siendo necesario combinar toda la información en una nueva columna\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d568f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_movements'...\n",
      "Tabla 'accounting_movements' cargada exitosamente. Filas: 7020, Columnas: 22\n",
      "\n",
      "Combinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\n",
      "Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\n",
      "Columnas originales ['item_id', 'references_document_id', 'payroll_employee_reference_id'] eliminadas.\n",
      "\n",
      "Primeras 5 filas del DataFrame con las nuevas columnas de referencia:\n",
      "  primary_reference_type  primary_reference_id\n",
      "0                   Item                 394.0\n",
      "1                   Item                 394.0\n",
      "2                   Item                 394.0\n",
      "3                   Item                 394.0\n",
      "4                   Item                 394.0\n",
      "\n",
      "Conteo de nulos para las nuevas columnas de referencia:\n",
      "primary_reference_type    0\n",
      "primary_reference_id      0\n",
      "dtype: int64\n",
      "\n",
      "Proceso de combinación de referencias completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DUVAN\\AppData\\Local\\Temp\\ipykernel_14852\\1707058357.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Payroll Employee' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n"
     ]
    }
   ],
   "source": [
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_movements' ---\n",
    "# *** IMPORTANTE: Si ya ejecutaste el código anterior, asegúrate de recargar el DataFrame ***\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_movements'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_movements = pd.read_sql('SELECT * FROM accounting_movements', engine)\n",
    "    print(f\"Tabla 'accounting_movements' cargada exitosamente. Filas: {df_accounting_movements.shape[0]}, Columnas: {df_accounting_movements.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_movements': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Crear las nuevas columnas combinadas ---\n",
    "print(\"\\nCombinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\")\n",
    "\n",
    "# Inicializar las nuevas columnas con valores nulos\n",
    "df_accounting_movements['primary_reference_type'] = np.nan\n",
    "df_accounting_movements['primary_reference_id'] = np.nan\n",
    "\n",
    "# Lógica de combinación con prioridad:\n",
    "# 1. payroll_employee_reference_id (más específico)\n",
    "# 2. references_document_id\n",
    "# 3. item_id\n",
    "\n",
    "# Condición 1: Cuando payroll_employee_reference_id tiene un valor\n",
    "cond_payroll = df_accounting_movements['payroll_employee_reference_id'].notna()\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_id'] = df_accounting_movements['payroll_employee_reference_id']\n",
    "\n",
    "# Condición 2: Cuando payroll_employee_reference_id es nulo, pero references_document_id no lo es\n",
    "cond_doc = (~cond_payroll) & (df_accounting_movements['references_document_id'].notna())\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_type'] = 'Document'\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_id'] = df_accounting_movements['references_document_id']\n",
    "\n",
    "# Condición 3: Cuando payroll_employee_reference_id y references_document_id son nulos, pero item_id no lo es\n",
    "cond_item = (~cond_payroll) & (~cond_doc) & (df_accounting_movements['item_id'].notna())\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_type'] = 'Item'\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_id'] = df_accounting_movements['item_id']\n",
    "\n",
    "# Para los casos donde ninguna de las referencias se llenó, primary_reference_type e _id quedarán como NaN.\n",
    "# Rellenar 'primary_reference_type' con 'N/A' para mayor claridad\n",
    "df_accounting_movements['primary_reference_type'] = df_accounting_movements['primary_reference_type'].fillna('N/A')\n",
    "\n",
    "print(\"Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\")\n",
    "\n",
    "# --- Paso 3: Opcional - Eliminar las columnas originales si ya no son necesarias ---\n",
    "# Asegúrate de que las columnas 'item_type' y 'document' (de las que hablamos en la revisión anterior)\n",
    "# también se incluyan aquí si no las necesitas más, ya que también tenían muchos nulos.\n",
    "# Aquí solo estoy eliminando las que pediste combinar.\n",
    "columns_to_drop = ['item_id', 'references_document_id', 'payroll_employee_reference_id']\n",
    "# Si también quieres eliminar 'item_type' y 'document' (de la discusión previa), descomenta la línea de abajo:\n",
    "# columns_to_drop.extend(['item_type', 'document'])\n",
    "\n",
    "df_accounting_movements_cleaned = df_accounting_movements.drop(columns=columns_to_drop)\n",
    "print(f\"Columnas originales {columns_to_drop} eliminadas.\")\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas con las nuevas columnas ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame con las nuevas columnas de referencia:\")\n",
    "print(df_accounting_movements_cleaned[['primary_reference_type', 'primary_reference_id']].head())\n",
    "\n",
    "# --- Paso 5: Verificar el conteo de nulos para las nuevas columnas ---\n",
    "print(\"\\nConteo de nulos para las nuevas columnas de referencia:\")\n",
    "print(df_accounting_movements_cleaned[['primary_reference_type', 'primary_reference_id']].isnull().sum())\n",
    "\n",
    "print(\"\\nProceso de combinación de referencias completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d7927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'accounting_movements'...\n",
      "Tabla 'accounting_movements' cargada exitosamente. Filas: 7020, Columnas: 22\n",
      "\n",
      "Combinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\n",
      "Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\n",
      "Columnas originales ['item_id', 'references_document_id', 'payroll_employee_reference_id', 'item_type'] eliminadas.\n",
      "\n",
      "Primeras 5 filas del DataFrame con las nuevas columnas de referencia:\n",
      "   id primary_reference_type  primary_reference_id\n",
      "0  74                   Item                 394.0\n",
      "1  75                   Item                 394.0\n",
      "2  76                   Item                 394.0\n",
      "3  77                   Item                 394.0\n",
      "4  78                   Item                 394.0\n",
      "\n",
      "Conteo de nulos para las nuevas columnas de referencia:\n",
      "primary_reference_type    0\n",
      "primary_reference_id      0\n",
      "dtype: int64\n",
      "\n",
      "Columnas restantes en el DataFrame después de la limpieza: ['id', 'class_id', 'group_id', 'account_id', 'subaccount_id', 'accounting_movement', 'currency_id', 'name', 'date', 'debit_movement', 'credit_movement', 'third_party_type_id', 'third_party_id', 'document_type_id', 'document', 'document_id', 'created_at', 'updated_at', 'primary_reference_type', 'primary_reference_id']\n",
      "\n",
      "Proceso de combinación de referencias y eliminación de 'item_type' completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DUVAN\\AppData\\Local\\Temp\\ipykernel_14852\\289087782.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Payroll Employee' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de que get_engine() está definida en db_connection.py\n",
    "from db_connection import get_engine\n",
    "\n",
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'accounting_movements' ---\n",
    "# *** IMPORTANTE: Si ya ejecutaste el código anterior, asegúrate de recargar el DataFrame ***\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'accounting_movements'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_accounting_movements = pd.read_sql('SELECT * FROM accounting_movements', engine)\n",
    "    print(f\"Tabla 'accounting_movements' cargada exitosamente. Filas: {df_accounting_movements.shape[0]}, Columnas: {df_accounting_movements.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'accounting_movements': {e}\")\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Crear las nuevas columnas combinadas ---\n",
    "print(\"\\nCombinando columnas 'item_id', 'references_document_id', y 'payroll_employee_reference_id'...\")\n",
    "\n",
    "# Inicializar las nuevas columnas con valores nulos\n",
    "df_accounting_movements['primary_reference_type'] = np.nan\n",
    "df_accounting_movements['primary_reference_id'] = np.nan\n",
    "\n",
    "# Lógica de combinación con prioridad:\n",
    "# 1. payroll_employee_reference_id (más específico)\n",
    "# 2. references_document_id\n",
    "# 3. item_id\n",
    "\n",
    "# Condición 1: Cuando payroll_employee_reference_id tiene un valor\n",
    "cond_payroll = df_accounting_movements['payroll_employee_reference_id'].notna()\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_type'] = 'Payroll Employee'\n",
    "df_accounting_movements.loc[cond_payroll, 'primary_reference_id'] = df_accounting_movements['payroll_employee_reference_id']\n",
    "\n",
    "# Condición 2: Cuando payroll_employee_reference_id es nulo, pero references_document_id no lo es\n",
    "cond_doc = (~cond_payroll) & (df_accounting_movements['references_document_id'].notna())\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_type'] = 'Document'\n",
    "df_accounting_movements.loc[cond_doc, 'primary_reference_id'] = df_accounting_movements['references_document_id']\n",
    "\n",
    "# Condición 3: Cuando payroll_employee_reference_id y references_document_id son nulos, pero item_id no lo es\n",
    "cond_item = (~cond_payroll) & (~cond_doc) & (df_accounting_movements['item_id'].notna())\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_type'] = 'Item'\n",
    "df_accounting_movements.loc[cond_item, 'primary_reference_id'] = df_accounting_movements['item_id']\n",
    "\n",
    "# Para los casos donde ninguna de las referencias se llenó, primary_reference_type e _id quedarán como NaN.\n",
    "# Rellenar 'primary_reference_type' con 'N/A' para mayor claridad\n",
    "df_accounting_movements['primary_reference_type'] = df_accounting_movements['primary_reference_type'].fillna('N/A')\n",
    "\n",
    "print(\"Columnas combinadas 'primary_reference_type' y 'primary_reference_id' creadas.\")\n",
    "\n",
    "# --- Paso 3: Opcional - Eliminar las columnas originales si ya no son necesarias ---\n",
    "# *** Hemos añadido 'item_type' a la lista de columnas a eliminar ***\n",
    "columns_to_drop = ['item_id', 'references_document_id', 'payroll_employee_reference_id', 'item_type']\n",
    "\n",
    "df_accounting_movements_cleaned = df_accounting_movements.drop(columns=columns_to_drop)\n",
    "print(f\"Columnas originales {columns_to_drop} eliminadas.\")\n",
    "\n",
    "# --- Paso 4: Mostrar las primeras filas con las nuevas columnas ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame con las nuevas columnas de referencia:\")\n",
    "# Ajusta las columnas a mostrar en head() si quieres ver otras además de las nuevas de referencia\n",
    "print(df_accounting_movements_cleaned[['id', 'primary_reference_type', 'primary_reference_id']].head())\n",
    "\n",
    "# --- Paso 5: Verificar el conteo de nulos para las nuevas columnas ---\n",
    "print(\"\\nConteo de nulos para las nuevas columnas de referencia:\")\n",
    "print(df_accounting_movements_cleaned[['primary_reference_type', 'primary_reference_id']].isnull().sum())\n",
    "\n",
    "# --- Paso 6: Verificar que item_type ha sido eliminada ---\n",
    "print(f\"\\nColumnas restantes en el DataFrame después de la limpieza: {df_accounting_movements_cleaned.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nProceso de combinación de referencias y eliminación de 'item_type' completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea229f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db740e1a",
   "metadata": {},
   "source": [
    "***4.Tabla accounting_voucher_items***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0d315",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ccc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_voucher_items':\n",
      "  - id (bigint unsigned)\n",
      "  - accounting_voucher_id (bigint unsigned)\n",
      "  - third_party_type_id (varchar(255))\n",
      "  - third_party_id (bigint unsigned)\n",
      "  - accounting_account_id (bigint unsigned)\n",
      "  - description (varchar(255))\n",
      "  - debit_movement (double(18,6))\n",
      "  - credit_movement (double(18,6))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_voucher_items;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_voucher_items':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68584359",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96a304",
   "metadata": {},
   "source": [
    "***5.Tabla accounting_vouchers***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0718190",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_vouchers':\n",
      "  - id (bigint unsigned)\n",
      "  - accounting_voucher_type_id (bigint unsigned)\n",
      "  - prefix (varchar(50))\n",
      "  - number (bigint)\n",
      "  - voucher_date (date)\n",
      "  - third_party_id (bigint unsigned)\n",
      "  - third_party_type_id (varchar(50))\n",
      "  - advance_account_payable_id (bigint unsigned)\n",
      "  - supplier_account_id (bigint unsigned)\n",
      "  - advance_account_receivable_id (bigint unsigned)\n",
      "  - cartera_account_id (bigint unsigned)\n",
      "  - currency_id (varchar(255))\n",
      "  - total_value (double(18,6))\n",
      "  - voucher_status_id (smallint unsigned)\n",
      "  - preferred (tinyint(1))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_vouchers;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_vouchers':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24da5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f1ac6",
   "metadata": {},
   "source": [
    "***6.Tabla accounting_voucher_types***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729fcf49",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'accounting_voucher_types':\n",
      "  - id (bigint unsigned)\n",
      "  - code (varchar(50))\n",
      "  - name (varchar(60))\n",
      "  - prefix (varchar(50))\n",
      "  - initial_number (bigint)\n",
      "  - current_number (bigint)\n",
      "  - ledger_id (int unsigned)\n",
      "  - status (tinyint(1))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE accounting_voucher_types;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'accounting_voucher_types':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4985e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c1c7c",
   "metadata": {},
   "source": [
    "***7.Tabla retention_concepts***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e65ec5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d094c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retention_concepts':\n",
      "  - id (int unsigned)\n",
      "  - description (text)\n",
      "  - account_id (bigint unsigned)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retention_concepts;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retention_concepts':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0f7664",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ca10f",
   "metadata": {},
   "source": [
    "***8.Tabla retentions***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae0be3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e7c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retentions':\n",
      "  - id (int unsigned)\n",
      "  - retention_type_id (varchar(255))\n",
      "  - retention_concept (int unsigned)\n",
      "  - description (varchar(255))\n",
      "  - percentage (double(10,5))\n",
      "  - uvt_base (double(18,6))\n",
      "  - base (double(18,6))\n",
      "  - notes (varchar(255))\n",
      "  - status (tinyint(1))\n",
      "  - account_id (bigint unsigned)\n",
      "  - user_id (int unsigned)\n",
      "  - is_custom (varchar(255))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retentions;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retentions':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d619f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b6a0a",
   "metadata": {},
   "source": [
    "***9.Tabla retentions_applied***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10697f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42084fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retentions_applied':\n",
      "  - id (bigint unsigned)\n",
      "  - name (varchar(255))\n",
      "  - type (varchar(255))\n",
      "  - percentage (double(18,6))\n",
      "  - base (double(18,6))\n",
      "  - value (double(18,6))\n",
      "  - retention_id (int unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - document_id (bigint unsigned)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retentions_applied;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retentions_applied':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97902b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd6ee3",
   "metadata": {},
   "source": [
    "***10.Tabla retentions_certificates***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0dd03c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d862148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'retentions_certificates':\n",
      "  - id (bigint unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - document_id (bigint unsigned)\n",
      "  - value (double(18,6))\n",
      "  - sent (tinyint(1))\n",
      "  - certificate_url (varchar(255))\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE retentions_certificates;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'retentions_certificates':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0bdd31",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44c4bd",
   "metadata": {},
   "source": [
    "***11.Tabla taxes***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b73da8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f500b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'taxes':\n",
      "  - id (smallint unsigned)\n",
      "  - tax_type_id (varchar(255))\n",
      "  - description (varchar(255))\n",
      "  - percentage (double(10,5))\n",
      "  - notes (varchar(255))\n",
      "  - status (tinyint(1))\n",
      "  - tax_account_deductible_id (bigint unsigned)\n",
      "  - tax_account_generated_id (bigint unsigned)\n",
      "  - user_id (int unsigned)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE taxes;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'taxes':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6bfd85",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2f4b2",
   "metadata": {},
   "source": [
    "***12.Tabla payments***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5dc199",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d10b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'payments':\n",
      "  - id (bigint unsigned)\n",
      "  - document_type_id (int unsigned)\n",
      "  - billing_numbering_id (int unsigned)\n",
      "  - payment_type (smallint unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - number (int unsigned)\n",
      "  - document_date (date)\n",
      "  - document_hour (time)\n",
      "  - associate_invoice (tinyint(1))\n",
      "  - reference_document (json)\n",
      "  - advance (tinyint(1))\n",
      "  - subtotal (double(16,2))\n",
      "  - discount (double(16,2))\n",
      "  - gross (double(16,2))\n",
      "  - pending (double(16,2))\n",
      "  - total (double(16,2))\n",
      "  - taxes (json)\n",
      "  - retentions_value (double(16,2))\n",
      "  - retentions (json)\n",
      "  - retentions_details (json)\n",
      "  - payments (json)\n",
      "  - notes (varchar(255))\n",
      "  - comments (varchar(255))\n",
      "  - document_status_id (smallint unsigned)\n",
      "  - DIAN_status (json)\n",
      "  - contact_data (json)\n",
      "  - details (json)\n",
      "  - extra_data (json)\n",
      "  - user_id (int unsigned)\n",
      "  - deleted_at (timestamp)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE payments;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'payments':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6528f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base de datos y cargando la tabla 'payments'...\n",
      "Tabla 'payments' cargada exitosamente. Filas: 614, Columnas: 32\n",
      "\n",
      "Iniciando aplanamiento de columnas JSON...\n",
      "Aplanando columna: 'reference_document'\n",
      "Columna 'reference_document' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'taxes'\n",
      "Columna 'taxes' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'retentions'\n",
      "Columna 'retentions' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'retentions_details'\n",
      "Columna 'retentions_details' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'payments'\n",
      "Columna 'payments' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'DIAN_status'\n",
      "Columna 'DIAN_status' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'contact_data'\n",
      "Columna 'contact_data' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'details'\n",
      "Columna 'details' aplanada y eliminada. Nuevas columnas añadidas.\n",
      "Aplanando columna: 'extra_data'\n",
      "ADVERTENCIA: No se pudo aplanar la columna 'extra_data' completamente. Error: Unable to allocate 182. MiB for an array with shape (14, 1704763) and data type int64\n",
      "Revisar la estructura JSON de 'extra_data' para un aplanamiento específico o manejar errores.\n",
      "\n",
      "Aplanamiento de campos JSON completado.\n",
      "Nuevo tamaño del DataFrame \"df_payments_flattened\": 7287 filas, 157 columnas.\n",
      "\n",
      "Primeras 5 filas del DataFrame 'df_payments_flattened':\n",
      "   id  document_type_id  billing_numbering_id  payment_type  contact_id  \\\n",
      "0   1                13                     3             0           2   \n",
      "1   2                13                     3             0           1   \n",
      "2   3                13                     3             0           7   \n",
      "3   4                13                     3             0           7   \n",
      "4   5                13                     3             0           1   \n",
      "\n",
      "   number document_date   document_hour  associate_invoice  advance  ...  \\\n",
      "0       1    2019-10-16 0 days 04:12:41                  1        0  ...   \n",
      "1       2    2019-10-16 0 days 05:56:17                  1        0  ...   \n",
      "2       3    2019-10-24 0 days 03:58:54                  1        0  ...   \n",
      "3       4    2019-10-24 0 days 04:00:50                  1        0  ...   \n",
      "4       5    2019-11-05 0 days 08:38:48                  1        0  ...   \n",
      "\n",
      "   details_retentions  details_discountValue  details_taxPercentage  \\\n",
      "0                 NaN                    NaN                    NaN   \n",
      "1                 NaN                    NaN                    NaN   \n",
      "2                 NaN                    NaN                    NaN   \n",
      "3                 NaN                    NaN                    NaN   \n",
      "4                 NaN                    NaN                    NaN   \n",
      "\n",
      "   details_unitSalePrice  details_taxDescription  details_discountPercentage  \\\n",
      "0                    NaN                     NaN                         NaN   \n",
      "1                    NaN                     NaN                         NaN   \n",
      "2                    NaN                     NaN                         NaN   \n",
      "3                    NaN                     NaN                         NaN   \n",
      "4                    NaN                     NaN                         NaN   \n",
      "\n",
      "  details_unitSalePriceNoTax details_headquarter  details_paymentAccount.id  \\\n",
      "0                        NaN                 NaN                        NaN   \n",
      "1                        NaN                 NaN                        NaN   \n",
      "2                        NaN                 NaN                        NaN   \n",
      "3                        NaN                 NaN                        NaN   \n",
      "4                        NaN                 NaN                        NaN   \n",
      "\n",
      "  details_paymentAccount.name  \n",
      "0                         NaN  \n",
      "1                         NaN  \n",
      "2                         NaN  \n",
      "3                         NaN  \n",
      "4                         NaN  \n",
      "\n",
      "[5 rows x 157 columns]\n",
      "\n",
      "Nuevas columnas añadidas (prefijadas por el nombre de la columna JSON original):\n",
      "['extra_data', 'reference_document_date', 'reference_document_total', 'reference_document_prefix', 'reference_document_invoice', 'reference_document_document_type_id', 'reference_document_billing_numbering_id', 'reference_document_document_id', 'taxes__id', 'taxes_base', 'taxes_type', 'taxes_value', 'taxes_percentage', 'taxes_description', 'retentions__id', 'retentions_base', 'retentions_type', 'retentions_value_retentions_dup', 'retentions_percentage', 'retentions_description', 'retentions_items', 'retentions_typeName', 'retentions_fromPayment', 'retentions_retentionId', 'retentions_details__id', 'retentions_details_base', 'retentions_details_type', 'retentions_details_value', 'retentions_details_typeName', 'retentions_details_percentage', 'retentions_details_description', 'retentions_details_retentionId', 'retentions_details_fromPayment', 'retentions_details_items', 'payments_value', 'payments_paymentMethodId', 'payments_paymentMethodDescription', 'payments_paymentReference', 'payments_affectedInvoices', 'payments_paymentAccount.id', 'payments_paymentAccount.name', 'payments_paymentValue', 'DIAN_status_date', 'DIAN_status_message', 'DIAN_status_status_id', 'contact_data_id', 'contact_data_city', 'contact_data_lead', 'contact_data_email', 'contact_data_group', 'contact_data_names', 'contact_data_notes', 'contact_data_phone', 'contact_data_client', 'contact_data_mobile', 'contact_data_region', 'contact_data_status', 'contact_data_address', 'contact_data_country', 'contact_data_user_id', 'contact_data_provider', 'contact_data_surnames', 'contact_data_zip_code', 'contact_data_extension', 'contact_data_full_name', 'contact_data_tenant_id', 'contact_data_created_at', 'contact_data_deleted_at', 'contact_data_updated_at', 'contact_data_check_digit', 'contact_data_obligations', 'contact_data_neighborhood', 'contact_data_business_name', 'contact_data_register_type', 'contact_data_person_type_id', 'contact_data_document_number', 'contact_data_iva_responsible', 'contact_data_economic_activity', 'contact_data_payment_condition_id', 'contact_data_tax_responsibility_id', 'contact_data_contributory_scheme_id', 'contact_data_identity_document_type_id', 'contact_data_tradename', 'contact_data_price_list_id', 'contact_data_max_billing_value', 'contact_data_photo', 'contact_data_e_user', 'contact_data_e_status', 'contact_data_dial_code', 'contact_data_main_contact', 'contact_data_from_ecommerce', 'contact_data_shipping_address', 'contact_data_e_register_source', 'contact_data_address_complement', 'contact_data_headquarter_id', 'contact_data_external_id', 'contact_data_national', 'contact_data_gender_id', 'contact_data_is_own_tenant_provider', 'details_id', 'details_paid', 'details_total', 'details_credit', 'details_number', 'details_prefix', 'details_pending', 'details_paymentValue', 'details_gross', 'details_index', 'details_ivaTotal', 'details_retentionsValue', 'details_aTotalRetentions', 'details_electronicBilling', 'details_prevRetentionsValue', 'details_prevTotalRetentions', 'details_aTotalRetentionsDetails', 'details_prevTotalRetentionsDetails', 'details_name', 'details_notes', 'details_taxId', 'details_taxType', 'details_quantity', 'details_taxTotal', 'details_taxValue', 'details_retentions', 'details_discountValue', 'details_taxPercentage', 'details_unitSalePrice', 'details_taxDescription', 'details_discountPercentage', 'details_unitSalePriceNoTax', 'details_headquarter', 'details_paymentAccount.id', 'details_paymentAccount.name']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import json # Necesario para parsear strings JSON si no son objetos nativos\n",
    "\n",
    "# Asegúrate de que get_engine() está definida en db_connection.py\n",
    "from db_connection import get_engine\n",
    "\n",
    "# --- Paso 1: Conectarse a la base de datos y cargar la tabla 'payments' ---\n",
    "print(\"Conectando a la base de datos y cargando la tabla 'payments'...\")\n",
    "try:\n",
    "    engine = get_engine()\n",
    "    df_payments = pd.read_sql('SELECT * FROM payments', engine)\n",
    "    print(f\"Tabla 'payments' cargada exitosamente. Filas: {df_payments.shape[0]}, Columnas: {df_payments.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar la tabla 'payments': {e}\")\n",
    "    # Considera salir o manejar el error adecuadamente si la carga falla\n",
    "    raise # Relanzar la excepción para detener la ejecución si falla la carga.\n",
    "\n",
    "# --- Paso 2: Identificar columnas JSON y aplanarlas ---\n",
    "# Definimos las columnas que identificamos como JSON\n",
    "json_columns = [\n",
    "    'reference_document',\n",
    "    'taxes',\n",
    "    'retentions',\n",
    "    'retentions_details',\n",
    "    'payments', # Ojo: esta es la columna 'payments' en la tabla 'payments'.\n",
    "    'DIAN_status',\n",
    "    'contact_data',\n",
    "    'details',\n",
    "    'extra_data'\n",
    "]\n",
    "\n",
    "# Crear una copia del DataFrame para trabajar y mantener el original si es necesario\n",
    "df_payments_flattened = df_payments.copy()\n",
    "\n",
    "print(\"\\nIniciando aplanamiento de columnas JSON...\")\n",
    "\n",
    "for col in json_columns:\n",
    "    if col in df_payments_flattened.columns:\n",
    "        print(f\"Aplanando columna: '{col}'\")\n",
    "        \n",
    "        # Convertir strings JSON a objetos Python (si no lo son ya)\n",
    "        # Usamos .astype(str) para asegurar que el contenido sea string antes de json.loads,\n",
    "        # lo que puede ayudar si hay valores no-string (ej., números)\n",
    "        df_payments_flattened[col] = df_payments_flattened[col].astype(str).apply(\n",
    "            lambda x: json.loads(x) if isinstance(x, str) and x.strip() and x.startswith(('[', '{')) else None\n",
    "        )\n",
    "\n",
    "        # Filtrar solo las filas donde el JSON no es nulo y es un diccionario/lista\n",
    "        valid_json_data = df_payments_flattened[df_payments_flattened[col].apply(lambda x: isinstance(x, (dict, list)) and x is not None)][col]\n",
    "        \n",
    "        # Obtener los índices de las filas con JSON válido para unir correctamente\n",
    "        valid_indices = valid_json_data.index\n",
    "\n",
    "        if not valid_json_data.empty:\n",
    "            try:\n",
    "                # Comprobar si el JSON es una lista (para aplanamiento de múltiples registros por ID)\n",
    "                # O si es un diccionario (para aplanamiento de claves a columnas)\n",
    "                \n",
    "                # Para el caso de 'payments' (la columna, no la tabla) o cualquier otra que sea una lista de objetos:\n",
    "                if valid_json_data.apply(lambda x: isinstance(x, list)).any():\n",
    "                    # Explode la lista de JSONs en múltiples filas, manteniendo el ID original.\n",
    "                    # Esto es útil si un solo registro de pago tiene múltiples sub-pagos o ítems.\n",
    "                    # Crea un DataFrame temporal para la columna JSON aplanada\n",
    "                    temp_df = pd.json_normalize(valid_json_data.explode())\n",
    "                    temp_df.index = valid_json_data.explode().index # Asegurar que el índice coincida\n",
    "                    \n",
    "                    # Unir con el DataFrame principal. Añadir un prefijo claro.\n",
    "                    df_payments_flattened = df_payments_flattened.merge(\n",
    "                        temp_df.add_prefix(f'{col}_'),\n",
    "                        left_index=True,\n",
    "                        right_index=True,\n",
    "                        how='left',\n",
    "                        suffixes=('', f'_{col}_dup') # Sufijo para columnas duplicadas, si las hay\n",
    "                    )\n",
    "                else: # Asumir que es un diccionario o un solo objeto JSON\n",
    "                    # Aplanar el diccionario.\n",
    "                    # Se usa `record_path=None` si el JSON de la columna es un diccionario con las claves a aplanar.\n",
    "                    df_col_flattened = pd.json_normalize(valid_json_data)\n",
    "                    df_col_flattened.index = valid_indices # Mantener el índice original\n",
    "\n",
    "                    # Unir con el DataFrame original por el índice (id del pago)\n",
    "                    df_payments_flattened = df_payments_flattened.merge(\n",
    "                        df_col_flattened.add_prefix(f'{col}_'),\n",
    "                        left_index=True,\n",
    "                        right_index=True,\n",
    "                        how='left',\n",
    "                        suffixes=('', f'_{col}_dup')\n",
    "                    )\n",
    "\n",
    "                # Eliminar la columna original después de aplanarla\n",
    "                df_payments_flattened = df_payments_flattened.drop(columns=[col])\n",
    "                print(f\"Columna '{col}' aplanada y eliminada. Nuevas columnas añadidas.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ADVERTENCIA: No se pudo aplanar la columna '{col}' completamente. Error: {e}\")\n",
    "                print(f\"Revisar la estructura JSON de '{col}' para un aplanamiento específico o manejar errores.\")\n",
    "        else:\n",
    "            print(f\"La columna '{col}' no contiene datos JSON válidos o no es un diccionario/lista en las filas seleccionadas.\")\n",
    "    else:\n",
    "        print(f\"La columna '{col}' no existe en el DataFrame original. Saltando.\")\n",
    "\n",
    "\n",
    "print(\"\\nAplanamiento de campos JSON completado.\")\n",
    "# La línea corregida para el SyntaxError:\n",
    "print(f\"Nuevo tamaño del DataFrame \\\"df_payments_flattened\\\": {df_payments_flattened.shape[0]} filas, {df_payments_flattened.shape[1]} columnas.\")\n",
    "\n",
    "# --- Paso 3: Mostrar las primeras filas del DataFrame aplanado para verificar ---\n",
    "print(\"\\nPrimeras 5 filas del DataFrame 'df_payments_flattened':\")\n",
    "print(df_payments_flattened.head())\n",
    "\n",
    "# --- Paso 4: Mostrar las nuevas columnas creadas ---\n",
    "print(\"\\nNuevas columnas añadidas (prefijadas por el nombre de la columna JSON original):\")\n",
    "# Obtener las columnas antes de aplanar (excluyendo las originales JSON que se eliminaron)\n",
    "initial_non_json_cols = [c for c in df_payments.columns if c not in json_columns]\n",
    "new_cols = [col for col in df_payments_flattened.columns if col not in initial_non_json_cols]\n",
    "print(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44791e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conexión exitosa a la base de datos\n",
      "Columnas de la tabla 'payments':\n",
      "  - id (bigint unsigned)\n",
      "  - document_type_id (int unsigned)\n",
      "  - billing_numbering_id (int unsigned)\n",
      "  - payment_type (smallint unsigned)\n",
      "  - contact_id (int unsigned)\n",
      "  - number (int unsigned)\n",
      "  - document_date (date)\n",
      "  - document_hour (time)\n",
      "  - associate_invoice (tinyint(1))\n",
      "  - reference_document (json)\n",
      "  - advance (tinyint(1))\n",
      "  - subtotal (double(16,2))\n",
      "  - discount (double(16,2))\n",
      "  - gross (double(16,2))\n",
      "  - pending (double(16,2))\n",
      "  - total (double(16,2))\n",
      "  - taxes (json)\n",
      "  - retentions_value (double(16,2))\n",
      "  - retentions (json)\n",
      "  - retentions_details (json)\n",
      "  - payments (json)\n",
      "  - notes (varchar(255))\n",
      "  - comments (varchar(255))\n",
      "  - document_status_id (smallint unsigned)\n",
      "  - DIAN_status (json)\n",
      "  - contact_data (json)\n",
      "  - details (json)\n",
      "  - extra_data (json)\n",
      "  - user_id (int unsigned)\n",
      "  - deleted_at (timestamp)\n",
      "  - created_at (timestamp)\n",
      "  - updated_at (timestamp)\n",
      "Conexión y cursor cerrados.\n"
     ]
    }
   ],
   "source": [
    "# 1. Reconectar (o asegurar que la conexión esté activa)\n",
    "try:\n",
    "    conexion = get_connection()\n",
    "    cursor = conexion.cursor()\n",
    "\n",
    "    # 2. Ejecutar la consulta para describir la tabla\n",
    "    cursor.execute(\"DESCRIBE payments;\")\n",
    "    columns_info = cursor.fetchall()\n",
    "\n",
    "    print(\"Columnas de la tabla 'payments':\")\n",
    "    for column in columns_info:\n",
    "        print(f\"  - {column[0]} ({column[1]})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}\")\n",
    "finally:\n",
    "    # 3. Cerrar el cursor y la conexión de forma segura\n",
    "    if 'cursor' in locals() and cursor is not None:\n",
    "        cursor.close()\n",
    "    if 'conexion' in locals() and conexion.is_connected():\n",
    "        conexion.close()\n",
    "    print(\"Conexión y cursor cerrados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f4410c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e9557",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347b390",
   "metadata": {},
   "source": [
    "****GLOBAL****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61fa9fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50b7138",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'db_connection'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_engine\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Asegúrate de que get_engine() está definida en db_connection.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdb_connection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_engine\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Lista de todas las tablas que hemos analizado\u001b[39;00m\n\u001b[32m      8\u001b[39m tables_to_check = [\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccounting_account_balances\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccounting_accounts\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpayments\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     21\u001b[39m ]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'db_connection'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Asegúrate de que get_engine() está definida en db_connection.py\n",
    "from db_connection import get_engine\n",
    "\n",
    "# Lista de todas las tablas que hemos analizado\n",
    "tables_to_check = [\n",
    "    'accounting_account_balances',\n",
    "    'accounting_accounts',\n",
    "    'accounting_movements',\n",
    "    'accounting_voucher_items',\n",
    "    'accounting_voucher_types',\n",
    "    'accounting_vouchers',\n",
    "    'retention_concepts',\n",
    "    'retentions',\n",
    "    'retentions_applied',\n",
    "    'retentions_certificates',\n",
    "    'taxes',\n",
    "    'payments'\n",
    "]\n",
    "\n",
    "engine = None # Inicializar engine fuera del try para que sea accesible en finally\n",
    "\n",
    "try:\n",
    "    print(\"Conectando a la base de datos para revisar datos faltantes...\")\n",
    "    engine = get_engine()\n",
    "    print(\"Conexión a la base de datos establecida.\")\n",
    "\n",
    "    for table_name in tables_to_check:\n",
    "        print(f\"\\n--- Analizando datos faltantes en la tabla: '{table_name}' ---\")\n",
    "        try:\n",
    "            df = pd.read_sql(f'SELECT * FROM {table_name}', engine)\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"La tabla '{table_name}' está vacía. No hay datos que analizar.\")\n",
    "                continue\n",
    "\n",
    "            # Calcular la cantidad de valores nulos por columna\n",
    "            missing_values_count = df.isnull().sum()\n",
    "\n",
    "            # Calcular el porcentaje de valores nulos por columna\n",
    "            missing_values_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "            # Crear un DataFrame con el recuento y el porcentaje de nulos\n",
    "            missing_data_df = pd.DataFrame({\n",
    "                'Missing Count': missing_values_count,\n",
    "                'Missing Percentage': missing_values_percentage\n",
    "            })\n",
    "\n",
    "            # Filtrar solo las columnas que tienen valores faltantes\n",
    "            missing_data_df = missing_data_df[missing_data_df['Missing Count'] > 0].sort_values(by='Missing Percentage', ascending=False)\n",
    "\n",
    "            if missing_data_df.empty:\n",
    "                print(f\"No se encontraron valores faltantes en la tabla '{table_name}'.\")\n",
    "            else:\n",
    "                print(\"Valores faltantes por columna:\")\n",
    "                print(missing_data_df)\n",
    "\n",
    "            # Opcional: Visualización simple para tablas más pequeñas\n",
    "            # import matplotlib.pyplot as plt\n",
    "            # import seaborn as sns\n",
    "            # if not missing_data_df.empty:\n",
    "            #     plt.figure(figsize=(10, 6))\n",
    "            #     sns.barplot(x=missing_data_df.index, y='Missing Percentage', data=missing_data_df)\n",
    "            #     plt.title(f'Porcentaje de Valores Faltantes en {table_name}')\n",
    "            #     plt.ylabel('Porcentaje Faltante (%)')\n",
    "            #     plt.xticks(rotation=45, ha='right')\n",
    "            #     plt.tight_layout()\n",
    "            #     plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar o analizar la tabla '{table_name}': {e}\")\n",
    "            print(f\"Asegúrate de que la tabla '{table_name}' existe y es accesible.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error general de conexión a la base de datos: {e}\")\n",
    "finally:\n",
    "    if engine:\n",
    "        # Asegúrate de cerrar la conexión si es un motor que lo requiere explícitamente\n",
    "        # Para SQLAlchemy con un pool, esto no siempre es necesario o deseable.\n",
    "        # Pero es buena práctica si la conexión directa lo requiere.\n",
    "        # En general, el `engine` de SQLAlchemy maneja el pool de conexiones.\n",
    "        pass # La gestión de conexiones con `engine` de SQLAlchemy es automática.\n",
    "    print(\"\\nProceso de revisión de datos faltantes completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e4903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
